##User Agent Settings
user.agent=Mozilla/5.0 (Windows NT 6.1; WOW64; rv:25.0) Gecko/20100101 Firefox/25.0
user.agent.random.enabled=false
##connection params
connection.timeout=20000
read.timeout=20000
url.redirects.enabled=true
##Crawler settings
crawler.max.depth=10
## This in multiples of 10 secs Ex: If value is 30, then its 300 secs which is 5 mins
# Crawler waits for 5 mins before shutting down, if no more URLs are to be crawled
crawler.max.waiting.time=30
##Thread pool configuration for each service
service.starter.thread.count=4
webcrawler.service.thread.count=2
parser.service.thread.count=2
##Service Names
response.output.generation.service.name=Response Generator
sitemap.output.generation.service.name=SiteMap Generator
response.output.generation.file.name=response.txt
sitemap.output.generation.file.name=siteMap.txt
input.urls.file.name=inputUrls.txt
user.agents.file.name=userAgents.txt
##Services to be started
#Available services: Crawler,Parser,SiteMapGenerator,ResponseGenerator, if all services are required pass "all" string
#crawler.services.list=Crawler,Parser,SiteMapGenerator,ResponseGenerator
crawler.services.list=all







